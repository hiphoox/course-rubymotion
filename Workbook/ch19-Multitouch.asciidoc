Chapter 19 - Multitouch
=======================

One of the best features of the iPhone or iPad is the touch screen. In this chapter we will use it to make an app for drawing on the screen.


Kanji Master
------------

One of the most difficult languages to learn is Japanese because they use one symbol (Kanji) to express full concepts. This is different than most languages because they use words (Multiple symbols: letters) for the same purpose.

In this exercise we will create a app that will teach the user how to draw a Kanji, allowing him to paint the shape with his fingers on the screen.

.Kanji
image::resources/ch19-Multitouch/ch19_Kanji.png[Kanji]


Preparing the Canvas
~~~~~~~~~~~~~~~~~~~~

Let's start creating a new project called **KanjiMaster**:

[source, sh]
------------
$ motion create KanjiMaster
------------

Please copy the resources from **resources/images** folder into the project resources folder; after that create the following file:

[source, sh]
------------
$ cd KanjiMaster/app

$ mkdir views

$ touch kanji_view.rb

$ open kanji_view.rb
------------

Now add the following to our **kanji_view.rb** file:

[source, ruby]
--------------
class KanjiView < UIView

  def initWithFrame(frame)

    if super

      # In order to not hide the background image on
      # the controllers view, we need to set the background color on
      # this view as transparent
      self.backgroundColor = UIColor.clearColor

      # We need to set multipleTouchEnabled to true if we want to handle
      # more than one finger touching the screen
      self.multipleTouchEnabled = true

      # Create an Array instance for storing the user touches
      @touch_points = NSMutableArray.alloc.init
    end

    self

  end

end
--------------

Let's create a controller for our new view with the name **KanjiViewController**:

[source, sh]
------------
$ cd ..

$ mkdir controllers

$ cd controllers

$ touch kanji_view_controller.rb

$ open kanji_view_controller.rb
------------

Insert the following into the **kanji_view_controller.rb** file:

[source, ruby]
------------
class KanjiViewController < UIViewController

  def loadView

    self.view = UIView.alloc.initWithFrame(UIScreen.mainScreen.bounds)

    # Create a new UIImageView to draw our background image
    background_image_view = UIImageView.alloc.initWithFrame(self.view.bounds)

    # Set our background image in the UIImageView
    background_image_view.image = UIImage.imageNamed("bgKanji")

    # Add the UIImageView instance into the view
    self.view.addSubview(background_image_view)

    # Load our custom UIView (KanjiView)
    kanjiView = KanjiView.alloc.initWithFrame(self.view.bounds)

    # Add it to our view controller's view
    self.view.addSubview(kanjiView)
  end

end
------------

Finally let's open our **app_delegate.rb** and add the following:

[source, sh]
------------
$ cd ..

$ open app_delegate.rb
------------

[source, ruby]
--------------
class AppDelegate

  def application(application, didFinishLaunchingWithOptions:launchOptions)

    #Create an instance of Kanji View Controller
    kanji_view_controller = KanjiViewController.alloc.init

    @window = UIWindow.alloc.initWithFrame(UIScreen.mainScreen.bounds)

    #Every window has a root view controller from which it will present its view
    @window.rootViewController = kanji_view_controller
    @window.makeKeyAndVisible

    true
  end

end
--------------

If we run the app, you should see the following:

[source, sh]
------------
$ rake
------------

.Initial Application
image::resources/ch19-Multitouch/ch19_InitialApplication.png[Initial Application]


The Responder Chain
~~~~~~~~~~~~~~~~~~~
If you look closely on the project that we just created, we have to implement a custom view called **KanjiView**. The purpose of this is that we can catch the touch events on it. But why on a UIView?

When the user touches the screen, a new event is created and sent as a message to the first responder (the most foremost view in the hierarchy). If it cannot handle the message, it is forwarded to the "next responder" and so on. This linked series is called **Responder Chain**

In iOS (not as same as Mac) both UIViews and UIViewControllers are part of the **Responder Chain**, but typically just the Views can handle the touch events. This happens because by default the UIViewControllers cannot become first responders.

According to the above, we need an object that can become the first responder and be in the responder chain so it can handle the touch events. This object is generally a UIView.

IMPORTANT: If you need by any reason to handle the touch events on your controller, you can override the method **canBecomeFirstResponder** to allow it to become first responder.


Handling the Touches
~~~~~~~~~~~~~~~~~~~~
Now that we understand the Responder Chain, how to handle the touches? The response is implementing the following methods on our view:

[source, ruby]
--------------
# This method is called when the finger (or fingers) touch the screen for the first time
def touchesBegan(touches, withEvent: event)

# This method is called when the finger (or fingers) are moving without leaving the screen
def touchesMoved(touches, withEvent: event)

# This method is called when the finger (or fingers) leave the screen
def touchesEnded(touches, withEvent:event)
--------------

For testing proposes let's implement it on our **KanjiView** the following way:

[source, ruby]
--------------
# This method is called when the finger (or fingers)
# touch the screen for the first time
def touchesBegan(touches, withEvent: event)

  #  Touches is a set of UITouch, each of them
  #  representing a diferent finger on the screen
  touches.allObjects.each_with_index { | touch, index |

    # We need to ask the touch for its location according
    # to the current view
    pointInView = touch.locationInView(self)

    NSLog("Touch %@ starting on %@", index + 1, NSStringFromCGPoint(pointInView))
  }

end

# This method is called when the finger (or fingers)
# are moving without leaving the screen
def touchesMoved(touches, withEvent: event)

  #  Touches is an set of UITouch, each of them
  #  represent a diferent finger on the screen
  touches.allObjects.each_with_index { | touch, index |

    # We need to ask the touch for its location according
    # to the current view
    pointInView = touch.locationInView(self)

    NSLog("Touch %@ moving to %@", index + 1, NSStringFromCGPoint(pointInView))
  }

end

# This method is called when the finger (or fingers)
# leave the screen
def touchesEnded(touches, withEvent:event)

  #  Touches is a set of UITouch, each of them
  #  representing a different finger on the screen
  touches.allObjects.each_with_index { | touch, index |

    # We need to ask the touch for its location according
    # to the current view
    pointInView = touch.locationInView(self)

    NSLog("Touch %@ ended at %@", index + 1, NSStringFromCGPoint(pointInView))
  }

end
--------------

If we run the application we should see the following when we touch the screen:

[source, sh]
------------
> Touch 1 starting on {147, 305}
> Touch 2 starting on {117, 205}
> Touch 1 moving to {151, 297}
> Touch 2 moving to {179, 327}
> Touch 1 moving to {153, 294}
> Touch 2 moving to {178, 323}
> Touch 1 moving to {155, 289}
> Touch 2 moving to {179, 326}
> Touch 1 ended at {178, 319}
> Touch 2 ended at {198, 119}
------------

IMPORTANT: Are you using the iOS Simulator? No problem! You can also simulate multiple touches by pressing **alt**. If you need to move the multiple touches together press **alt + shift**


Painting the Touches
~~~~~~~~~~~~~~~~~~~~
Now that we have detected the touches, it's time to paint them on the screen. For that we will use a technology called CoreGraphics, but before we use it we need to understand some key concepts:

* If we want to draw on a UIView using CoreGraphics we need to do it in a method called **drawRect**, it's an override and shouldn't be implemented unless you will draw something (it affects performance when it's not drawing).

* The drawing on a UIView using Core Graphics is not additive. What this means is that I can't draw a line and then later when the user touches the screen draw another (I can't  call **drawRect** manually). For this reason, we need to store which lines will be painted and then call **setNeedsDisplay**. This method will clear the entire view and then call **drawRect** again, forcing repainting of everything again.

Using the above information let's implement the user touches on the screen:

["source","ruby", args="-O \"hl_lines=46 49 50\""]
--------------
# Method where we need to do the Core Graphics drawing
def drawRect(rect)

  # Get the Core Graphics current context
  context = UIGraphicsGetCurrentContext()

  # Set a color for drawing the touch points
  UIColor.colorWithRed(0.988, green:0.612, blue:0.157, alpha:1.0).set

  # Iterate the touch points
  @touch_points.each { | touch_point |

    # Move the context to the touch point
    CGContextMoveToPoint(context,
                         touch_point.CGPointValue.x,
                         touch_point.CGPointValue.y)

    # Create a rect in which want to the ellipse be drawn
    point_rect = CGRectMake(touch_point.CGPointValue.x - 10,
                            touch_point.CGPointValue.y - 10,
                            20,
                            20)

    # Add the ellipse using the rect into the context
    CGContextAddEllipseInRect(context, point_rect)

    # Draw the context into the view
    CGContextFillPath(context)
  }
end

# This method is called when the finger (or fingers)
# touch the screen for the first time
def touchesBegan(touches, withEvent: event)

  #  Touches is a set of UITouch, each of them
  #  representing a diferent finger on the screen
  touches.allObjects.each_with_index { | touch, index |

    # We need to ask the touch for its location according
    # to the current view
    pointInView = touch.locationInView(self)

    # Add the point to our array. As the point is a structure (CGPoint),
    # we need to store it on a NSValue
    @touch_points.addObject(NSValue.valueWithCGPoint(pointInView))
  }

  # Ask the view to redraw again
  self.setNeedsDisplay

end
--------------

.Initial Touches
image::resources/ch19-Multitouch/ch19_InitialTouches.png[Initial Touches]

Great! Now we are really seeing where the user touches began, let's continue adding the touch movements:

IMPORTANT: If you are using a simulator probably you will notice that the dot is painted down right of the cursor. This is normal because iOS handles the mouse click as the top left corner of a finger.

["source","ruby", args="-O \"hl_lines=13 16\""]
--------------
# This method is called when the finger (or fingers)
# are moving without leaving the screen
def touchesMoved(touches, withEvent: event)

  #  Touches is an set of UITouch, each of them
  #  represent a diferent finger on the screen
  touches.allObjects.each_with_index { | touch, index |

    # We need to ask the touch for its location according
    # to the current view
    pointInView = touch.locationInView(self)

    @touch_points.addObject(NSValue.valueWithCGPoint(pointInView))
  }

  self.setNeedsDisplay
end
--------------

.Initial Lines
image::resources/ch19-Multitouch/ch19_InitialLines.png[Initial Lines]

Now we are drawing the initial touches and the movement in the screen, it looks like a line but if we move the finger faster will become more like a dotted line right? No problem we will fix that later


Kanji Drawing
~~~~~~~~~~~~~
We just played a bit with the touches and drawing for us to feel comfortable about how it works. Now let's do something more challenging:

If we look at our background picture, we have a Kanji with traces marked with numbers. The objective is create a little game for the user to draw the Kanji.  Our first task is to determine if the user is following the traces or not.

.Starting Points
image::resources/ch19-Multitouch/ch19_StartingPoints.png[Starting Points]


The first thing we can do is to have an array of the trace starting coordinates, that will enable us to evaluate if the touch was on the beginning. let's do a little experiment to test this part:

["source","ruby", args="-O \"hl_lines=13 45 46 47 48 49 50 51 52 53 54 55 56 59 60 61 62 63 64 65 66 67 68\""]
--------------
def initWithFrame(frame)

  if super

    # In order to not hide the background image on
    # the controllers view, we need to set the background color on
    # this view as transparent
    self.backgroundColor = UIColor.clearColor

    # Create an Array instance for storing the user touches
    @touch_points = NSMutableArray.alloc.init

    load_kanji_traces
  end

  self

end

def load_kanji_traces

  # Create an array to store our Kanji Paths
  @kanji_traces = NSMutableArray.alloc.init

  # As a experiment let's add only the starting point of
  # the trace number three
  kanji_starting_trace_three = CGPointMake(150, 260)


  # Add the point to the Kanji Paths array
  @kanji_traces.addObject(NSValue.valueWithCGPoint(kanji_starting_trace_three))
end



# This method is called when the finger (or fingers)
# touch the screen for the first time
def touchesBegan(touches, withEvent: event)

  # We need to ask the touch for its location according
  # to the current view
  pointInView = touches.anyObject.locationInView(self)


  touch_at_beginning = false

  # Iterate through all the Kanji Paths available
  @kanji_traces.each { | kanji_trace |

    # If the touched point is equal to any Kanji Trace starting
    # point, set touch_at_beginning to true
    if CGPointEqualToPoint(kanji_trace.CGPointValue, pointInView)

      touch_at_beginning = true
    end
  }


  # If the touch was at the beginning of any Kanji Trace
  if touch_at_beginning

    # Add the point to our array. As the point is a structure (CGPoint),
    # we need to store it on a NSValue
    @touch_points.addObject(NSValue.valueWithCGPoint(pointInView))

    # Ask the view to redraw again
    self.setNeedsDisplay
  end

end
--------------

Impossible do it with the first touch (Without moving the touch), right? This is because we are comparing a small point in the screen with the width of a finger, making it difficult to touch with precision. The solution is to create a rectangle surrounding the starting trace point, making it easier to hit it with the finger.

Also we need to evaluate if the user is following the trace and if the trace ended where it should. For this we will use rectangles as well. In the light of this, it is better to create a object for all these variables.

IMPORTANT: Remember it does not matter if it is a point, rectangle or a button, it needs to be big enough for the user to touch.

Let's create our new class **KanjiTrace**:

[source, sh]
------------
$ cd ..

$ cd mkdir models

$ cd models

$ touch kanji_trace.rb

$ open kanji_trace.rb
------------


[source, ruby]
--------------
class KanjiTrace

  SURROUND_SIZE = 40

  attr_accessor :starting_point
  attr_accessor :end_point


  def initial_rectangle

    CGRectMake(starting_point.x - SURROUND_SIZE,
               starting_point.y - SURROUND_SIZE,
               SURROUND_SIZE * 2,
               SURROUND_SIZE * 2)
  end


  def final_rectangle

    CGRectMake(end_point.x - SURROUND_SIZE,
               end_point.y - SURROUND_SIZE,
               SURROUND_SIZE * 2,
               SURROUND_SIZE * 2)

  end

end
--------------

Great! Now we have a object containing the trace start and end points and it returns the surrounding rectangles. Let's implement the **KanjiTrace** class into our **kanji_view.rb**:

[source, sh]
------------
$ cd ..

$ cd controllers

$ open kanji_view.rb
------------

["source","ruby", args="-O \"hl_lines=7 8 9 10 11 12 13 14 33 34 35 36 37 38 39 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60\""]
--------------
def load_kanji_traces

  # Create an array to store our Kanji Paths
  @kanji_traces = NSMutableArray.alloc.init


  # Continuing the experiment create only a Kanji Trace
  # for the trace number three
  trace_three = KanjiTrace.new

  trace_three.starting_point = CGPointMake(150, 260)

  # Add the point to the Kanji Paths array
  @kanji_traces.addObject(trace_three)
end



# This method is called when the finger (or fingers)
# touch the screen for the first time
def touchesBegan(touches, withEvent: event)

  # We need to ask the touch for its location according
  # to the current view
  pointInView = touches.anyObject.locationInView(self)


  touch_at_beginning = false

  # Iterate through all the Kanji Paths available
  @kanji_traces.each { | kanji_trace |

    # If the touched point exists in the Kanji Trace
    # rectangle
    if CGRectContainsPoint(kanji_trace.initial_rectangle, pointInView)

      # Assign the trace that the user is currently
      # drawing
      @current_trace = kanji_trace
      touch_at_beginning = true
    end
  }


  # If the touch was at the beginning of any Kanji Trace
  if touch_at_beginning

    # Add the point to our array. As the point is a structure (CGPoint),
    # we need to store it on a NSValue
    @touch_points.addObject(NSValue.valueWithCGPoint(pointInView))

    # Ask the view to redraw again
    self.setNeedsDisplay

  else

    # If there is no touch at the beginning means
    # that the user is not drawing a new trace
    @current_trace = nil
  end

end
--------------

.Start Trace #3
image::resources/ch19-Multitouch/ch19_StartTrace3.png[Start Trace #3]

It's working now! It's easier for the user to touch the start of the trace, so let's continue adding the all the Kanji Traces:
Be sure to update or remove trace_three!

[source, ruby]
--------------
def load_kanji_traces

  # Create an array to store our Kanji Paths
  @kanji_traces = NSMutableArray.alloc.init


  trace_one = KanjiTrace.new
  trace_one.starting_point = CGPointMake(40, 300)
  trace_one.end_point = CGPointMake(273, 282)

  @kanji_traces.addObject(trace_one)

  trace_two = KanjiTrace.new
  trace_two.starting_point = CGPointMake(155, 285)
  trace_two.end_point = CGPointMake(289, 366)

  @kanji_traces.addObject(trace_two)

  trace_three = KanjiTrace.new
  trace_three.starting_point = CGPointMake(150, 260)
  trace_three.end_point = CGPointMake(152, 367)

  @kanji_traces.addObject(trace_three)

  trace_four = KanjiTrace.new
  trace_four.starting_point = CGPointMake(31, 366)
  trace_four.end_point = CGPointMake(145, 294)

  @kanji_traces.addObject(trace_four)

  trace_five = KanjiTrace.new
  trace_five.starting_point = CGPointMake(225, 175)
  trace_five.end_point = CGPointMake(226, 140)

  @kanji_traces.addObject(trace_five)

  trace_six = KanjiTrace.new
  trace_six.starting_point = CGPointMake(219, 202)
  trace_six.end_point = CGPointMake(277, 237)

  @kanji_traces.addObject(trace_six)

  trace_seven = KanjiTrace.new
  trace_seven.starting_point = CGPointMake(69, 191)
  trace_seven.end_point = CGPointMake(33, 160)

  @kanji_traces.addObject(trace_seven)

  trace_eight = KanjiTrace.new
  trace_eight.starting_point = CGPointMake(85, 211)
  trace_eight.end_point = CGPointMake(40, 247)

  @kanji_traces.addObject(trace_eight)

  trace_nine = KanjiTrace.new
  trace_nine.starting_point = CGPointMake(109, 171)
  trace_nine.end_point = CGPointMake(185, 159)

  @kanji_traces.addObject(trace_nine)

  trace_ten = KanjiTrace.new
  trace_ten.starting_point = CGPointMake(190, 171)
  trace_ten.end_point = CGPointMake(186, 241)

  @kanji_traces.addObject(trace_ten)

  trace_eleven = KanjiTrace.new
  trace_eleven.starting_point = CGPointMake(175, 227)
  trace_eleven.end_point = CGPointMake(114, 235)

  @kanji_traces.addObject(trace_eleven)

  trace_twelve = KanjiTrace.new
  trace_twelve.starting_point = CGPointMake(112, 223)
  trace_twelve.end_point = CGPointMake(112, 181)

  @kanji_traces.addObject(trace_twelve)

  trace_thirteen = KanjiTrace.new
  trace_thirteen.starting_point = CGPointMake(114, 161)
  trace_thirteen.end_point = CGPointMake(140, 129)

  @kanji_traces.addObject(trace_thirteen)

end
--------------

.All Starting Traces
image::resources/ch19-Multitouch/ch19_AllStartingTraces.png[All Starting Traces]

Yes! We can start painting on any trace now. Let's continue adding a method to our **KanjiTrace** for evaluate if the user is following the line and assigning a score for the drawing:

[source, sh]
------------
$ cd ..

$ cd models

$ open "kanji_trace.rb"
------------

[source, ruby]
--------------
attr_reader :accurate_points

def evaluate_point(point)

  # let's create properties to store the accurate touches of
  # the user and the missing ones
  @accurate_points ||= 0
  @missing_points ||= 0

  # The next step is creating a surrounding rectangle for the
  # trace, make it more easy for the user to touch
  trace_rect = CGRectMake([starting_point.x, end_point.x].min - SURROUND_SIZE,
                          [starting_point.y, end_point.y].min - SURROUND_SIZE,
                          (starting_point.x - end_point.x).abs + SURROUND_SIZE * 2,
                          (starting_point.y - end_point.y).abs + SURROUND_SIZE * 2)


  # If the point is in the trace
  if CGRectContainsPoint(trace_rect, point)

    # Add one to the accurate points
    @accurate_points += 1
  else

    # Add one to the missing points
    @missing_points += 1
  end

end
--------------

Our **KanjiTrace** is now evaluating and recording the score, next step is to used in our **kanji_view.rb** on the touchesMoved method:

[source, sh]
------------
$ cd ..

$ cd views

$ open kanji_view.rb
------------


["source","ruby", args="-O \"hl_lines=10 11 12 13 14 15 16 17 18 19 20 21 22 23\""]
--------------
# This method is called when the finger (or fingers)
# are moving without leaving the screen
def touchesMoved(touches, withEvent: event)

  # We need to ask the touch for its location according
  # to the current view
  pointInView = touches.anyObject.locationInView(self)


  # If the user is drawing a trace
  unless @current_trace.nil?

    # Add the touch point into the array, so it can be
    # drawing later
    @touch_points.addObject(NSValue.valueWithCGPoint(pointInView))

    # Evaluate how accurate the touch is in relationship
    # to the trace
    @current_trace.evaluate_point(pointInView)

    # Ask for repainting
    self.setNeedsDisplay
  end

end
--------------

Now we are keeping a score about how accurate is the user drawing, but we are not doing nothing with it! Our next step is just about that!

.Painted Trace
image::resources/ch19-Multitouch/ch19_PaintedTrace.png[Painted Trace]

High Score!
~~~~~~~~~~~
So as the Kanji description tell us there is a technique for building cups of tea, so what about adding some disable cups on the top of the app to symbolize the score of the user (3 disable cups mean 0 right?)

So the first thing will be to copy the images in **resources/images** folder into our app resource's folder. Next add the follow to the **kanji_view.rb**:

["source","ruby", args="-O \"hl_lines=13\""]
--------------
def initWithFrame(frame)

  if super

    # In order to not hide the background image on
    # the controllers view, we need to set the background color on
    # this view as transparent
    self.backgroundColor = UIColor.clearColor

    # Create an Array instance for storing the user touches
    @touch_points = NSMutableArray.alloc.init

    layout_cups
    load_kanji_traces

  end

  self

end


def layout_cups

  first_cup_frame = CGRectMake(55, 29, 50, 50)

  @first_cup_image_view = UIImageView.alloc.initWithFrame(first_cup_frame)

  @first_cup_image_view.image = UIImage.imageNamed('bgRakuOff1.png')

  self.addSubview(@first_cup_image_view)


  second_cup_frame = CGRectMake(135, 29, 50, 50)

  @second_cup_image_view = UIImageView.alloc.initWithFrame(second_cup_frame)

  @second_cup_image_view.image = UIImage.imageNamed('bgRakuOff2.png')

  self.addSubview(@second_cup_image_view)


  third_cup_frame = CGRectMake(215, 29, 50, 50)

  @third_cup_image_view = UIImageView.alloc.initWithFrame(third_cup_frame)

  @third_cup_image_view.image = UIImage.imageNamed('bgRakuOff3.png')

  self.addSubview(@third_cup_image_view)

end
--------------

.Score Board
image::resources/ch19-Multitouch/ch19_ScoreBoard.png[Score Board]

The last part of the exercise consist of analyzing the score of all the traces and according to that, change the images of the cups. Making a little scoreboard!

["source","ruby", args="-O \"hl_lines=4\""]
--------------
# Method where we need to do the Core Graphics drawing
def drawRect(rect)

  update_score_board

  # Get the Core Graphics current context
  context = UIGraphicsGetCurrentContext()

  # Set a color for drawing the touch points
  UIColor.colorWithRed(0.988, green:0.612, blue:0.157, alpha:0.6).set

  # Iterate the touch points
  @touch_points.each { | touch_point |

    # Move the context to the touch point
    CGContextMoveToPoint(context,
                         touch_point.CGPointValue.x,
                         touch_point.CGPointValue.y)

  # Create a rect in which want to the ellipse be drawn
  point_rect = CGRectMake(touch_point.CGPointValue.x - 10,
                          touch_point.CGPointValue.y - 10,
                          20,
                          20)

  # Add the ellipse using the rect into the context
  CGContextAddEllipseInRect(context, point_rect)

  # Draw the context into the view
  CGContextFillPath(context)
  }
end


def update_score_board
  total_accurate_points = 0

  @kanji_traces.each { | kanji_trace |
    unless kanji_trace.accurate_points.nil?
      total_accurate_points += kanji_trace.accurate_points
    end
  }

  if total_accurate_points >= 100
    @first_cup_image_view.image = UIImage.imageNamed('bgRakuOn1.png')
  end

  if total_accurate_points >= 300
    @second_cup_image_view.image = UIImage.imageNamed('bgRakuOn2.png')
  end

  if total_accurate_points >= 500
    @third_cup_image_view.image = UIImage.imageNamed('bgRakuOn3.png')
  end
end
--------------

.High Score
image::resources/ch19-Multitouch/ch19_HighScore.png[High Score]

Now it's finished! It looks like it will need some animations for the cups to look amazing, in the next chapters we will see how to make animations.

Challenges
~~~~~~~~~~
. Restart the game when the user double tap the screen (Hint: tapCount)

. Implement a point subtraction of the trace score for when the user draws outside the trace, but without losing the ability to get the maximum score.

. The current implementation is drawing every point into the view, the challenge is change that into drawing just one line starting in the first touch and ending when the user removes the finger (Hint: CGContextAddLineToPoint)

